

import numpy as np
from scipy.linalg import eigh
from sklearn.cluster import KMeans

# 设置numpy全局打印选项
np.set_printoptions(precision=2, suppress=True)

# 数据集
X = np.array([
    [2, 3, 2],
    [1, 2, 1],
    [1, 1, 1],
    [2, 2, 2],
    [4, 2, 4],
    [4, 1, 4],
    [5, 1, 5]
])
# print(X.shape)
# X = np.array([
#     [1, 1],
#     [1, 2],
# ])

# 高斯核函数
def gaussian_kernel(x1, x2, sigma=1):
    t = -np.linalg.norm(x1 - x2)**2 / (2 * (sigma**2))
    return np.exp(t)

# 构建带权邻接矩阵W
n = X.shape[0]
print(n) # 7

W = np.zeros((n, n))
# print(W)
# [[0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]
#  [0. 0. 0. 0. 0. 0. 0.]]
# exit(0)

for i in range(n):
    for j in range(i, n):
        W[i, j] = W[j, i] = gaussian_kernel(X[i], X[j])
# [[1.00000000e+00 2.23130160e-01 4.97870684e-02 6.06530660e-01 1.11089965e-02 2.47875218e-03 1.67017008e-05]
#  [2.23130160e-01 1.00000000e+00 6.06530660e-01 3.67879441e-01 1.23409804e-04 7.48518299e-05 6.82560338e-08]
#  [4.97870684e-02 6.06530660e-01 1.00000000e+00 2.23130160e-01 7.48518299e-05 1.23409804e-04 1.12535175e-07]
#  [6.06530660e-01 3.67879441e-01 2.23130160e-01 1.00000000e+00 1.83156389e-02 1.11089965e-02 7.48518299e-05]
#  [1.11089965e-02 1.23409804e-04 7.48518299e-05 1.83156389e-02 1.00000000e+00 6.06530660e-01 2.23130160e-01]
#  [2.47875218e-03 7.48518299e-05 1.23409804e-04 1.11089965e-02 6.06530660e-01 1.00000000e+00 3.67879441e-01]
#  [1.67017008e-05 6.82560338e-08 1.12535175e-07 7.48518299e-05 2.23130160e-01 3.67879441e-01 1.00000000e+00]]
# print(W)
# exit(0)



# 计算度矩阵D
D = np.diag(W.sum(axis=1))
# print(D)
# [[1.89305234 0. 0. 0. 0. 0. 0.]
#  [0. 2.19773859 0. 0. 0. 0. 0.]
#  [0. 0. 1.87964626 0. 0. 0. 0.]
#  [0. 0. 0. 2.22703975 0. 0. 0.]
#  [0. 0. 0. 0. 1.85928372 0. 0.]
#  [0. 0. 0. 0. 0. 1.98819611 0.]
#  [0. 0. 0. 0. 0. 0. 1.59110134]]
# exit(0)

# 拉普拉斯矩阵L
L = D - W
# print(L)
# exit(0)
# [[ 8.93052339e-01 -2.23130160e-01 -4.97870684e-02 -6.06530660e-01 -1.11089965e-02 -2.47875218e-03 -1.67017008e-05]
#  [-2.23130160e-01  1.19773859e+00 -6.06530660e-01 -3.67879441e-01 -1.23409804e-04 -7.48518299e-05 -6.82560338e-08]
#  [-4.97870684e-02 -6.06530660e-01  8.79646262e-01 -2.23130160e-01 -7.48518299e-05 -1.23409804e-04 -1.12535175e-07]
#  [-6.06530660e-01 -3.67879441e-01 -2.23130160e-01  1.22703975e+00 -1.83156389e-02 -1.11089965e-02 -7.48518299e-05]
#  [-1.11089965e-02 -1.23409804e-04 -7.48518299e-05 -1.83156389e-02 8.59283717e-01 -6.06530660e-01 -2.23130160e-01]
#  [-2.47875218e-03 -7.48518299e-05 -1.23409804e-04 -1.11089965e-02 -6.06530660e-01  9.88196111e-01 -3.67879441e-01]
#  [-1.67017008e-05 -6.82560338e-08 -1.12535175e-07 -7.48518299e-05 -2.23130160e-01 -3.67879441e-01  5.91101336e-01]]

# 计算L的特征值和特征向量
eigenvalues, eigenvectors = eigh(L) # 特征值和特征向量已按升序排列
# print(eigenvalues) # [-2.22044605e-16  2.47658240e-02  7.57116289e-01  8.72437247e-01 1.55245692e+00  1.66878668e+00  1.76049514e+00]
# print(eigenvectors)
# exit(0)

# 提取前k个特征值对应的特征向量（k=2）
k = 2
H = eigenvectors[:, :k]
print(eigenvalues[ :k]) # [-2.22044605e-16  2.47658240e-02]
# print(H)
# exit(0)

# 数据集Y（每一行对应新的数据点）
Y = np.array(H)
print("数据集Y：\n", Y)
print(Y.shape)

# 初始簇心
centroids = Y[:2]

# 创建 KMeans 模型
kmeans = KMeans(init='random', n_clusters=k, n_init=10)

# 使用初始簇心进行聚类
kmeans.fit(Y)

# 获取最终簇心和簇分配结果
final_centroids = kmeans.cluster_centers_
final_clusters = kmeans.labels_

print("最终簇心：\n", final_centroids)
print("簇分配：", final_clusters)
